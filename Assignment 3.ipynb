{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Carissa Chung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model  Training Accuracy  Validation Accuracy\n",
      "0     DT          44.431977            78.530777\n",
      "1     DT          55.753645            58.129774\n",
      "2     DT          44.577429            74.883797\n",
      "3     DT          44.972729            81.353143\n",
      "4     DT          46.663022            74.339164\n",
      "5     RF          30.175139            44.702896\n",
      "6     RF          30.497811            40.810587\n",
      "7     RF          29.521419            47.628153\n",
      "8     RF          28.310466            42.369915\n",
      "9     RF          28.831935            50.393784\n",
      "10    GB           3.655991            20.985837\n",
      "11    GB           3.610096            18.614374\n",
      "12    GB           3.603710            22.223800\n",
      "13    GB           2.478394            24.891893\n",
      "14    GB           3.549009            27.200200\n",
      "\n",
      "        Training Accuracy  Validation Accuracy\n",
      "Model                                        \n",
      "DT             47.279761            73.447331\n",
      "GB              3.379440            22.783221\n",
      "RF             29.467354            45.181067\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Step 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Define a list of models\n",
    "models = [\n",
    "    (\"DT\", DecisionTreeRegressor(max_depth=5, random_state=0)),\n",
    "    (\"RF\", RandomForestRegressor(n_estimators=200, max_depth=5, random_state=0)),\n",
    "    (\"GB\", GradientBoostingRegressor(max_depth=5, random_state=0))\n",
    "]\n",
    "\n",
    "# Create lists to store results\n",
    "model_names = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "# Iterate through models\n",
    "for model_name, model in models:\n",
    "    model_names.extend([model_name] * 5)  # Extend model names for each fold\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    \n",
    "    # Calculate training accuracy using cross_val_score\n",
    "    train_scores = -scores['train_score']\n",
    "    training_accuracy.extend(train_scores)\n",
    "    \n",
    "    # Calculate validation accuracy using cross_val_score\n",
    "    val_scores = -scores['test_score']\n",
    "    validation_accuracy.extend(val_scores)\n",
    "\n",
    "# Step 5\n",
    "# Create a DataFrame to store the results\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Training Accuracy': training_accuracy,\n",
    "    'Validation Accuracy': validation_accuracy\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results)\n",
    "\n",
    "# Group the results by 'Model' and calculate the mean\n",
    "mean_results = results.groupby('Model').mean()\n",
    "\n",
    "# Print the mean results\n",
    "print(\"\\n\", mean_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model  Training Accuracy  Validation Accuracy\n",
      "0     DT           0.848558             0.686485\n",
      "1     DT           0.800906             0.810192\n",
      "2     DT           0.843391             0.743552\n",
      "3     DT           0.845048             0.698323\n",
      "4     DT           0.834424             0.754932\n",
      "5     RF           0.897151             0.821534\n",
      "6     RF           0.891093             0.866743\n",
      "7     RF           0.896285             0.836892\n",
      "8     RF           0.902457             0.842882\n",
      "9     RF           0.897694             0.833871\n",
      "10    GB           0.987539             0.916219\n",
      "11    GB           0.987108             0.939219\n",
      "12    GB           0.987339             0.923892\n",
      "13    GB           0.991461             0.907695\n",
      "14    GB           0.987407             0.910331\n",
      "\n",
      "        Training Accuracy  Validation Accuracy\n",
      "Model                                        \n",
      "DT              0.834465             0.738697\n",
      "GB              0.988171             0.919471\n",
      "RF              0.896936             0.840385\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Define a list of models\n",
    "models = [\n",
    "    (\"DT\", DecisionTreeRegressor(max_depth=5, random_state=0)),\n",
    "    (\"RF\", RandomForestRegressor(n_estimators=200, max_depth=5, random_state=0)),\n",
    "    (\"GB\", GradientBoostingRegressor(max_depth=5, random_state=0))\n",
    "]\n",
    "\n",
    "# Create lists to store results\n",
    "model_names = []\n",
    "training_accuracy_r2 = []\n",
    "validation_accuracy_r2 = []\n",
    "\n",
    "# Iterate through models\n",
    "for model_name, model in models:\n",
    "    model_names.extend([model_name] * 5)  # Extend model names for each fold\n",
    "\n",
    "    scores_r2 = cross_validate(model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "    # Calculate training accuracy using cross_val_score\n",
    "    train_scores_r2 = scores_r2['train_score']\n",
    "    training_accuracy_r2.extend(train_scores_r2)\n",
    "    \n",
    "    # Calculate validation accuracy using cross_val_score\n",
    "    val_scores_r2 = scores_r2['test_score']\n",
    "    validation_accuracy_r2.extend(val_scores_r2)\n",
    "\n",
    "data_r2 = {\n",
    "    'Model': model_names,\n",
    "    'Training Accuracy': training_accuracy_r2,\n",
    "    'Validation Accuracy': validation_accuracy_r2\n",
    "}\n",
    "\n",
    "results_r2 = pd.DataFrame(data_r2)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results_r2)\n",
    "\n",
    "# Group the results by 'Model' and calculate the mean\n",
    "mean_results_r2 = results_r2.groupby('Model').mean()\n",
    "\n",
    "# Print the mean results\n",
    "print(\"\\n\", mean_results_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1. Compared to the solutions from the previous assignment (linear model), all three of the non-linear models resulted in lower mean squared error (MSE) values. For the linear regression (LR) model, MSEs for the training and validation were 111.36 and 95.90 on average, respectively. For the decision tree (DT) model, average MSEs of 47.28 and 73.45 were achieved for training and validation, respectively. Lower average MSEs were calculated for the random forest (RF) model, 29.47 and 45.18, with the gradient boosting (GB) model having the lowest average MSEs of 3.38 for training and 22.78 for validation. The lower the MSE, the better the model's performance, and the closer its predictions are to the actual values. Inversely, the higher the MSE, the worst the model's performance. In more detail, a lower MSE indicates that on average, the model's predictions were closer to the actual values which means that the model has a smaller average error in its predictions. A lower training MSE is expected during the training phase since the model should learn to minimize errors on the training data. However, a substantially higher validation MSE compared to the training MSE suggests that the model may not generalize well and might be overfitting the training data. For all three of the non-linear models, this seems to be the case as the training MSE is not extremely low while having a much higher validation MSE. Thus, for the three non-linear models, I don't believe that there is overfitting of the training data. However for the linear model, a higher training MSE was observed compared to the validation MSE. This is not a typical scenario and could be caused by non-random splitting of data into the training and validation sets where the training dataset may have had more challenging data. In addition, there may be outliers in the data that a linear model may not be able to represent accurately. \n",
    "\n",
    "Regarding the R2 scores, a much better performance was observed for the three non-linear models compared to the linear model. For the linear model, an average training R2 score of 0.61 and an average validation R2 score of 0.62 were observed. In comparison, the DT model had training and validation average R2 scores of 0.83 and 0.74, respectively. Out of the three non-linear models, the DT model performed the worst. The RF model achieved average training and validation R2 scores of 0.90 and 0.84, respectively where as the GB model achieved 0.99 and 0.92, respectively. Since the R2 score is a statistical measure that is used to evaluate the goodness of fit of a regression model, a higher R2 score indicates that the model is able to better explain the variance in the target based on the features of the dataset. R2 scores range from 0 to 1, where a R2 score of 0 indicates that the model is a poor fit to the data. Thus based on the results, the higher training R2 score for the non-linear models suggests that the model fits the training data well and can explain a significant portion of the variance in the target in the training set. A signficantly lower validation R2 score relative to the training R2 score may indicate overfitting where the model may not be able to generalize well to the new and unseen validation data. However, for the three non-linear models, the validation R2 scores are not significantly lower than the training R2 score and thus, overfitting is most likely not occuring. However, similar to the MSE observations, the linear model resulted in a lower training R2 score compared to the validation R2 score. The same conclusions can be drawn for this scenario and further investigation should be conducted as this most likely indicates that something is amiss in the modeling process or that the linear model is not an appropriate model for the data. \n",
    "\n",
    "In general, the goal is to strike a balance between minimizing training MSE while ensuring that validation MSE remains reasonably low, indicating good generalization to new data. Similarly, one should aim for a relatively high R2 training score while also achieving a high validation R2 score. Minimizing the difference between these two R2 values may be a good indication of a good fitting model with the ability to generalize well to new data Techniques like regularization and cross-validation can help prevent overfitting and achieve a better balance between training and validation performance.\n",
    "\n",
    "2. For the Decision Tree (DT) model, the results showed moderate training (0.83) and validation (0.74) accuracy. In addition, the model seems to have limited accuracy and might be overfitting because the training accuracy is quite a bit higher than the validation accuracy. For the Random Forest (RF) model, the results showed higher training (0.90) and validation (0.84) accuracy compared to DT. This is an indication of improved generalization. Although the training and validation accuracies are relatively high, the Gradient Boosting (GB) model showed much higher accuracies (0.99 and 0.92 for training and validation, respectively). In addition, GB can be robust against overfitting, especially with adequate hyperparameter tuning. This is because in GB, individual trees are not analyzed separately. Instead, all trees are averaged together so the trees that over fit will be averaged with under fitting trees. This results in an average that will be less likely to over fit or under fit the data. However, GB may be more computationally expensive and thus, require more time to train.\n",
    "\n",
    "Overall, it appears that the Gradient Boosting model consistently provides the best performance in terms of both training and validation accuracy. If predictive accuracy is the primary goal, and the computational resources are not a limiting factor, Gradient Boosting is a good choice. However, if computational resources are limited, RF is a good compromise between predictive accuracy and computational efficiency. \n",
    "\n",
    "3. a) Hyperparameter Tuning - thorough hyperparameter tuning can be used to find the optimal settings for the model. Some of these hyperparameters include tree depth (max_depth), the minimum number of samples required to split an internal node (min_samples_split), and the number of trees in the forest (for Random Forest). For Gradient Boosting, you can optimize parameters like the learning rate, the number of estimators (trees), and the maximum depth of each tree. Similar to the above exercses, cross-validation could be used to evaluate the model's performance for each set of hyperparameters.\n",
    "\n",
    "b) Feature Engineering - analyze and preprocess the dataset to improve the quality of input features. Feature engineering could include,\n",
    "- Creating new features to capture valuable information\n",
    "- Removing irrelevant features that may introduce noise\n",
    "- Effective handling of missing data\n",
    "- Scaling or normalizing features to ensure features are on a similar scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. The code was sourced from the Jupyter Notebooks for lecture and lab examples. In addition, the https://scikit-learn.org/ website was referenced for more details on the model parameters. The other source of the code was from ChatGPT. ChatGPT was referenced to make the looping portion of code I had written to populate the results table more efficient.\n",
    "2. All steps were completed in the order they were presented in the assignment.\n",
    "3. As mentioned previously, ChatGPT was used to make the for loop more efficient to populate the results table. The prompt incorporated the for loop I had written and a simple statement, \"For the code below, refactor the for loop to be more efficient\". The resulting code had to be modified to extract just the test_scores and train_scores from cross_validate.\n",
    "4. The biggest challenge was determining the best way to incorporate a for loop to efficiently populate the results table. ChatGPT was helpful in explaining the reasoning behind the resulting code and why it was done this way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a41f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33583c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import wine dataset\n",
    "def load_wine():\n",
    "    '''Load and pre-process wine data\n",
    "    \n",
    "    if wine.data file is not present.\n",
    "    \n",
    "    it will be downloaded from\n",
    "    https://archive.ics.uci.edu/dataset/109/wine.data\n",
    "    \n",
    "    return: data(DataFrame)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    import os\n",
    "    import requests\n",
    "    \n",
    "    \n",
    "    file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "    file_name = file_url.split('/')[-1]\n",
    "    \n",
    "    if not os.path.isfile(file_name):\n",
    "        print('Downloading from {}'.format(file_url))\n",
    "        r = requests.get(file_url)\n",
    "        with open(file_name,'wb') as output_file:\n",
    "            output_file.write(r.content)\n",
    "        \n",
    "    data = pd.read_csv(file_name, \n",
    "                   na_values='?', \n",
    "                   names=[ 'class', 'alcohol', 'malic acid', 'ash', 'alcalinity of ash', 'magnesium',\n",
    "                            'total phenols', 'flavanoids', 'nonflavanoid phenols', 'proanthocyanins', 'color intensity',\n",
    "                            'hue', 'OD280/OD315 of diluted wines', 'proline'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity of ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  alcohol  malic acid   ash  alcalinity of ash  magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   total phenols  flavanoids  nonflavanoid phenols  proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   color intensity   hue  OD280/OD315 of diluted wines  proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data = load_wine()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                           0\n",
       "alcohol                         0\n",
       "malic acid                      0\n",
       "ash                             0\n",
       "alcalinity of ash               0\n",
       "magnesium                       0\n",
       "total phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid phenols            0\n",
       "proanthocyanins                 0\n",
       "color intensity                 0\n",
       "hue                             0\n",
       "OD280/OD315 of diluted wines    0\n",
       "proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e156c867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X:\n",
      "alcohol                         float64\n",
      "malic acid                      float64\n",
      "ash                             float64\n",
      "alcalinity of ash               float64\n",
      "magnesium                         int64\n",
      "total phenols                   float64\n",
      "flavanoids                      float64\n",
      "nonflavanoid phenols            float64\n",
      "proanthocyanins                 float64\n",
      "color intensity                 float64\n",
      "hue                             float64\n",
      "OD280/OD315 of diluted wines    float64\n",
      "proline                           int64\n",
      "dtype: object\n",
      "Size of X: 2314\n",
      "Shape of X: (178, 13)\n",
      "X size=(178, 13); type=<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "\n",
      "\n",
      "Type of y:\n",
      "int64\n",
      "Size of y: 178\n",
      "Shape of y: (178,)\n",
      "y size=(178,); type=<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix and target vector and print shapes\n",
    "X = data.drop(columns='class')\n",
    "y = data['class']\n",
    "print(f\"Type of X:\\n{X.dtypes}\\nSize of X: {X.size:.0f}\\nShape of X: {X.shape}\")\n",
    "print(f\"X size={X.shape}; type={type(X)}\")\n",
    "\n",
    "print (\"\\n\")\n",
    "\n",
    "print(f\"\\nType of y:\\n{y.dtypes}\\nSize of y: {y.size:.0f}\\nShape of y: {y.shape}\")\n",
    "print(f\"y size={y.shape}; type={type(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine samples of class 1:  59\n",
      "Wine samples of class 2:  71\n",
      "Wine samples of class 3:  48\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "mask1 = data['class'] == 1\n",
    "data1 = data.copy()[mask1]\n",
    "print(\"Wine samples of class 1: \", data1['class'].count())\n",
    "\n",
    "mask2 = data['class'] == 2\n",
    "data2 = data.copy()[mask2]\n",
    "print(\"Wine samples of class 2: \", data2['class'].count())\n",
    "\n",
    "mask3 = data['class'] == 3\n",
    "data3 = data.copy()[mask3]\n",
    "print(\"Wine samples of class 3: \", data3['class'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model  Training Accuracy  Validation Accuracy\n",
      "0   SVC           0.679245             0.592593\n",
      "1   SVC           0.660377             0.703704\n",
      "2   SVC           0.688679             0.740741\n",
      "3   SVC           0.682243             0.653846\n",
      "4   SVC           0.691589             0.692308\n",
      "5    DT           1.000000             0.888889\n",
      "6    DT           0.990566             0.962963\n",
      "7    DT           0.990566             0.925926\n",
      "8    DT           0.990654             0.884615\n",
      "9    DT           1.000000             0.807692\n",
      "\n",
      "        Training Accuracy  Validation Accuracy\n",
      "Model                                        \n",
      "DT              0.994357             0.894017\n",
      "SVC             0.680427             0.676638\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "# Step 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Define a list of models\n",
    "models = [\n",
    "    (\"SVC\", SVC(random_state=0)),\n",
    "    (\"DT\", DecisionTreeClassifier(max_depth=3, random_state=0))\n",
    "]\n",
    "\n",
    "# Create lists to store results\n",
    "model_names = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "# Iterate through models\n",
    "for model_name, model in models:\n",
    "    model_names.extend([model_name] * 5)  # Extend model names for each fold\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    \n",
    "    # Calculate training accuracy using cross_val_score\n",
    "    train_scores = scores['train_score']\n",
    "    training_accuracy.extend(train_scores)\n",
    "    \n",
    "    # Calculate validation accuracy using cross_val_score\n",
    "    val_scores = scores['test_score']\n",
    "    validation_accuracy.extend(val_scores)\n",
    "\n",
    "# Step 5\n",
    "# Create a DataFrame to store the results\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Training Accuracy': training_accuracy,\n",
    "    'Validation Accuracy': validation_accuracy\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results)\n",
    "\n",
    "# Group the results by 'Model' and calculate the mean\n",
    "mean_results = results.groupby('Model').mean()\n",
    "\n",
    "# Print the mean results\n",
    "print(\"\\n\", mean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f36f4b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.9812378769176512\n",
      "Validation accuracy:  0.7148148148148149\n"
     ]
    }
   ],
   "source": [
    "# Specifying parameters for SVC\n",
    "\n",
    "svc_model = SVC(gamma=0.001, C=10, random_state=0)\n",
    "scores = cross_validate(svc_model, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "train_acc = scores['train_score']\n",
    "val_acc = scores['test_score']\n",
    "\n",
    "print(\"Training accuracy: \", train_acc.mean())\n",
    "print(\"Validation accuracy: \", val_acc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "model = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(170.97222222222223, 0.5, 'true value')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_val, model.predict(X_val))\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        59\n",
      "           1       0.96      0.99      0.97        71\n",
      "           2       0.98      1.00      0.99        48\n",
      "\n",
      "    accuracy                           0.98       178\n",
      "   macro avg       0.98      0.98      0.98       178\n",
      "weighted avg       0.98      0.98      0.98       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true=y, y_pred=model.predict(X), target_names=['0', '1', '2'], )\n",
    "print(report);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1. For the Support Vector Machines (SVC) model, the training accuracy varies from around 0.66 to 0.69 across each cross-validation run with an average of 0.68. The validation accuracy ranges from around 0.59 to 0.74 with an average of 0.68. On the other hand, for the Decision Trees (DT) model, the training accuracy for is consistently high, around 0.99 to 1.0. The validation accuracy ranged from 0.81 to 0.96. The DT model consistently outperformed the SVC model in both training and validation accuracy. Since the DT model achieved near-perfect training accuracy, this suggests that the model has learned the training data very well. However, it shows some variability in validation accuracy, indicating that it performs well on most validation sets but may overfit in some cases. For the SVC model, it achieved lower training and validation accuracies which may indicate that it might not capture the underlying patterns in the data as effectively as the DT model.\n",
    "2. The first reason the SVC model did not work as well as the DT model could be due to model complexity. The SVC model may not be as flexible as the DT model since the DT can create complex decision boundaries, allowing it to fit the training data more closely. In contrast, the SVC's linear or kernel-based boundaries might not capture the data's patterns as effectively, leading to lower accuracy. The second reason could be due to hyperparameter tuning. Since the SVC model is very sensitive to the gamma (inverse of the width of the Gaussian kernel) and c (regularization parameter; limits the importance of each point) hyperparameters, it is more difficult to tune and thus, the SVC model may not have been appropriately tuned. Since no hyperparameters were specified when defining the SVC model in this exercise, it is very likely that this could be the reason why the SVC model did not perform as well as the DT model.\n",
    "3. In step 5.2, 3 samples were incorrectly classified. Two samples were predicted to be class 1 but are actually class 0. The other sample was predicted to be class 2 but is actually class 1.\n",
    "4. For this dataset, I believe precision is more important. This is because precision indicates the model's ability to correctly classify instances as positive (true positives) without misclassifying too many negatives as positives (minimizing false positives). High precision ensures that when the model predicts a particular cultivar (class), it's highly likely to be correct. Classifying a wine sample as coming from a cultivar when it doesn't can have consequences, depending on the application. For example, if a wine is falsely classified as belonging to a premium cultivar, it could lead to inaccurate labeling, quality issues, or economic losses. If the consequences of false positives are significant (e.g., economic costs, quality control issues), maximizing precision might be more important.\n",
    "\n",
    "For recall, it aims to minimize false negatives. False negatives could be significant if failing to classify a wine sample correctly results in a high-quality wine being mistakenly classified as from another cultivar. In the context of this dataset, high recall would mean that the model correctly identifies all instances of a specific cultivar, minimizing false negatives. If the differences between cultivars have important practical implications (e.g., for wine quality or safety), maximizing recall might be more important. For example, if a specific cultivar is associated with unique characteristics or quality, missing any of its samples might be undesirable.\n",
    "\n",
    "Depending on the specific goals, costs, and consequences of wine misclassification, the choice between recall and precision can be determined. Assuming that economic or quality control is crucial, precision may be more important. However, if it's crucial to avoid misclassifying wines of one particular cultivar, recall may be more important. This scenario may prove to be more important in particular cases (e.g., if there is a product recall and wines from a particular cultivar are being recalled). However, for the majority of cases, I believe that precision is more important in the case of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. The code was sourced from the Jupyter Notebooks for lecture and lab examples (in particular, Decision Tree Example Jupyter notebook). In addition, the https://scikit-learn.org/ website was referenced for more details on the model parameters. The other source of the code was from ChatGPT. ChatGPT was referenced to make the looping portion of code I had written to populate the results table more efficient (as mentioned in part 1 of the assignment).\n",
    "2. All steps were completed in the order they were presented in the assignment.\n",
    "3. As mentioned previously, ChatGPT was used to make the for loop more efficient to populate the results table. The prompt incorporated the for loop I had written and a simple statement, \"For the code below, refactor the for loop to be more efficient\". The resulting code had to be modified to extract just the test_scores and train_scores from cross_validate.\n",
    "4. The biggest challenge was determining the best way to incorporate a for loop to efficiently populate the results table. ChatGPT was helpful in explaining the reasoning behind the resulting code and why it was done this way. In addition, another challenge was determining whether precision or recall was more important as both cases could be argued for and against. To answer the question, I considered the use of the dataset and why wine anaylsis would be conducted in the first place. I concluded that wine analysis would most likely be conducted to determine the quality of the wine and thus, the economics surrounding the worth of the wine. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "\n",
    "For the regression portion (part 1), the results align with what was discussed during lectures. Since gradient boosting models are an ensemble method that combines multiple weak learners, the combination of the predictions of all these weak learners build on each other to form a more accurate model. Compared to the random forest model, the GB model have numerous hyperparameters that can be tuned to improve performace (e.g., learning rate, tree depth, etc.). In general, single decision trees tend to have high bias (underfitting) and low variance, while random forests reduce variance at the expense of potentially higher bias. However, gradient boosting strikes a good balance between bias and variance, resulting in a model that generalizes well to unseen data (validation score of 0.92 compared to DT, 0.74, and RF, 0.84).\n",
    "\n",
    "For the classification portion (part 2), the DT model produced better results compared to SVC model (0.89 compared to 0.68). As mentioned above, this could be due to the SVC model being highly sensitive to the chosen gamma and c hyperparameters. Since the hyperparameters were not specified, it may be the reason that the SVC model did not perform as well as it could if the parameters were optimized. When gamma=0.001, C=10, was specified for the SVC model, a training score of 0.98 and validation score of 0.71 was observed. Thus, with more precise tuning, the SVC model may be able to produce better results than the DT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "- I enjoyed seeing the results of the non-linear models compared to the linear model from the previous assignment. Knowing that the data was non-linear and seeing this confirmed by the results was interesting.\n",
    "- The questions at the end of each part of the assignment helped me to try to delve deeper into understanding the results and why they were observed. The challenging parts of the assignment was interpreting precision and recall and trying to determine what was more important based on the context of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Model  Training Accuracy  Validation Accuracy\n",
      "0  LinearSVC           0.962264             0.888889\n",
      "1  LinearSVC           0.877358             0.925926\n",
      "2  LinearSVC           0.952830             1.000000\n",
      "3  LinearSVC           0.897196             0.884615\n",
      "4  LinearSVC           0.971963             0.923077\n",
      "\n",
      "            Training Accuracy  Validation Accuracy\n",
      "Model                                            \n",
      "LinearSVC           0.932322             0.924501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caris\\Anaconda3\\envs\\ensf-611\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Define a list of models\n",
    "models = [\n",
    "    (\"LinearSVC\", LinearSVC(max_iter=5000))\n",
    "]\n",
    "\n",
    "# Create lists to store results\n",
    "model_names = []\n",
    "training_accuracy = []\n",
    "validation_accuracy = []\n",
    "\n",
    "# Iterate through models\n",
    "for model_name, model in models:\n",
    "    model_names.extend([model_name] * 5)  # Extend model names for each fold\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)\n",
    "    \n",
    "    # Calculate training accuracy using cross_val_score\n",
    "    train_scores = scores['train_score']\n",
    "    training_accuracy.extend(train_scores)\n",
    "    \n",
    "    # Calculate validation accuracy using cross_val_score\n",
    "    val_scores = scores['test_score']\n",
    "    validation_accuracy.extend(val_scores)\n",
    "\n",
    "# Step 5\n",
    "# Create a DataFrame to store the results\n",
    "data = {\n",
    "    'Model': model_names,\n",
    "    'Training Accuracy': training_accuracy,\n",
    "    'Validation Accuracy': validation_accuracy\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results)\n",
    "\n",
    "# Group the results by 'Model' and calculate the mean\n",
    "mean_results = results.groupby('Model').mean()\n",
    "\n",
    "# Print the mean results\n",
    "print(\"\\n\", mean_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "Based on the above results, I don't believe that Linear SVC is a good fit for the data. This is because the model failed to converge after a large number of iterations (5000) which indicates that the model is unable to fit the data. Thus, the model will be unable to reliably predict the classes of wine. Although the training and validation accuracies appear higher compared to SVC, it is hard to make any conclusions as the model failed to converge.\n",
    "\n",
    "I tried increasing the max_iter to 10000, 100000, and 1000000 but the model still could not converge. Thus, the model may not a good fit and may require too much computational resources to conduct enough iterations for the model to converge (if it will converge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
